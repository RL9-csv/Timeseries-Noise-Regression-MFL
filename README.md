<img width="777" height="555" alt="image" src="https://github.com/user-attachments/assets/3ffc9784-0854-43e4-bda4-9c5bd1d9cf53" />
<img width="777" height="555" alt="image" src="https://github.com/user-attachments/assets/572565cc-e68e-42d4-a1d6-b0d78daadd83" />


# Timeseries-Noise-Regression-MFL
# 누설자속탐상(MFL) 공정 센서 데이터 기반의 시계열 노이즈 회귀 예측

## 프로젝트 개요
### 누설자속탐상(MFL) 공정의 데이터 기반 최적화: 미래 신호값의 추세 예측을 통한 선제적 위험 감지

누설자속탐상(MFL) 검사 공정의 핵심은 장비의 정밀도를 유지하는 교정 작업입니다.

<img width="555" height="555" alt="image" src="https://github.com/user-attachments/assets/00c6ddfd-1de7-47e1-916b-18a31f9ca189" />

<누설자속탐상기>




"LOT(각 강종의 여러개의 강철바의 묶음) 변경 시 교정"이라는 현재 규칙은 생산 현장의 현실과 맞지 않아 자주 무시되며, 이는 측정값의 신뢰도 하락과 잠재적 불량품 발생의 원인이 되기도 합니다. 규칙을 절대적으로 고수를 하게 된다면 생산성이 저하되고, 무시를 하면 품질이 떨어지는 리스크가 증가하는 딜레마에 빠져있는 상황입니다. 

특히, 실제 위험 신호는 급격하게 튀는 단발성 스파이크나 급격히 하락하는 신호값이 아닌, 장비 상태가 점진적으로 악화되면서 나타나는 신호값의 완만한 우상향 추세가 위험 신호입니다. 해당 프로젝트는 이 문제에 집중하여, 미래(t+10) 시점의 강철바 노이즈 값을 예측하는 회귀 모델링 실험을 진행하였습니다. 

이는 단순히 미래의 한 지점에 대한 예측을 넘어, 현재(t) 시점과 예측된 미래(t+10) 시점 사이의 기울기를 계산할 수 있는 근거를 제공합니다. 또한 지속적으로 강철바가 들어올 때마다 미래 값에 대한 예측을 통해 만들어지는 신호값의 추세를 정량적으로 파악하여, 위험이 임계치에 도달하기 전에 선제적으로 대응할 수 있는 가능성을 제시합니다. 

최종적으로 개발된 LightGBM 회귀 분석기 모델은 미래(t+10) 시점의 노이즈 수준을 평균 R²: 0.728의 신뢰도와 MAE: 0.0065(종속변수 평균: 0.0745)의 절대 평균 오차값으로 예측을 함으로써, 시계열 데이터 기반의 추세 예측이 어떻게 미래의 위험을 감지하고, 교정 시점 판단의 근거가 될 수 있는지에 대한 잠재력의 가능성을 입증하였습니다. 

## 목차
### 1. 데이터 소개 및 EDA
### 2. t+1 시점 신호값 회귀 예측 모델링 실험
### 3. 문제 정의의 진화, t+10 시점 신호값 회귀 예측 모델링 실험
### 4. 최종 모델 검증: 전체 채널 확장 적용
### 5. 특잇값 분해와 주성분 분석
### 6. 최종 결론

## 1. 데이터 소개 및 EDA
해당 프로젝트에 사용된 데이터는 누설자속탐상(MFL) 공정에서 10개의 채널의 센서에서 수집된 시계열 데이터입니다. 

<img width="888" height="555" alt="image" src="https://github.com/user-attachments/assets/69b5bf2b-0d52-4126-917a-751d56b22561" />

<위아래로 각각 5개의 센서를 통해 강철바의 검사가 진행됩니다.>

<img width="555" height="555" alt="image" src="https://github.com/user-attachments/assets/155b5c59-945d-48e4-b118-b9274be99a2b" />

<실제 강철바가 누설자속탐상기에 투입되어 검사가 진행되는 공정 모습으로, 이 과정에서 10개 채널의 시계열 신호가 수집됩니다.>

## 용어 설명
해당 프로젝트에서 센서는 강철철바의 결함 신호를 측정하는 검사 장치를 의미하며, 위아래로 각 5개씩 위치 하여있습니다. 여기서 위에 위치한 센서들은 CH-A1, CH-A2, CH-A3, CH-A4, CH-A5 A채널, 아래에 위치한 센서들은 CH-B1, CH-B2, CH-B3, CH-B4, CH-B5 B채널로 구분됩니다. 

## 데이터의 핵심 구조적 특성
각 데이터 파일은 하나의 강철바에 해당하며, 기업측과 보안 서약으로 인해 원본 데이터를 직접 공개할 수 없는 점 양해 부탁드립니다.

1-1. 미시적(Micro) 복접성: 단일 강철바 내부의 복잡한 신호값

하나의 강철바 내부에서 수집된 10개 채널의 원본 신호 값은 아래와 같이 매우 변동성이 크고 복잡한 패턴을 보입니다. 

<img width="1592" height="790" alt="1bar" src="https://github.com/user-attachments/assets/78065829-dfa5-4645-96e3-327d85d03e1e" />
<하나의 강철바에 대한 데이터>

1-2. 거시적(Macro) 단절성: LOT 변경 시 발생하는 신호 리셋

해당 데이터의 도전 과제의 핵심은 거시적 구조에 있습니다. 아래 그래프는 LOT가 변경이 될 때의 신호 변화를 보여줍니다. LOT가 변경될 때마다(강종 변경, 장비 교정이 규칙에 따라 정상적으로 이루어졌을 경우) 이전 시계열 패턴이 완전히 단절이 되고, 신호값이 새로운 기준선에서 시작되는 것을 확인 할 수 있습니다.

<img width="1489" height="690" alt="LOT star   end" src="https://github.com/user-attachments/assets/b66d7957-205d-47c2-98c9-67b67d60542c" />
<LOT 변경시 발생하는 신호값의 변화>

1-3. 데이터 병합 및 구조 

원본 85,841개 강철바 파일에서 여러 누락 또는 결측 파일을 제거하여 최종적으로 약 85,377개의 강철바 데이터를 확보하였습니다. 
확보된 데이터들을 시간 순서를 기준으로 메타 데이터에 기재된 정보들과 같이 하나의 데이터 프레임으로 통합을 하였습니다. 본래 데이터는 85,377의 행을 가지지만 추후 진행되는 실험에서 종속변수 생성 과정에서 로직 특성상 통합된 데이터의 행이 드랍이 되면서 행의 개수가 줄어들게 됩니다. 


## 2. t+1 시점 신호값 회귀 예측 모델링 실험

2-1. 종속변수 설정 근거

본래 프로젝트는 t+1 시점의 신호값을 예측하는 것에서부터 시작이 되었습니다. 

다단계 예측(Multi-step Ahead Forecast)의 특성
- 불확실성 증가: 예측 시점이 t+1 에서 t+h(h>1)로 멀어질수록 현재(t) 시점의 정보 영향력은 자연스럽게 감소합니다. 또한 t 시점과 t+h 시점 사이의 수많은 잠재적 변수를 모두 고려해야 하기 때문에 예측의 불확실성은 필연적으로 크게 증가합니다.
- 정밀도 저하: 이로 인해 t+1 예측에 비해 예측치의 신뢰 구간이 훨씬 넓어지며, 예측의 정밀도 또한 필연적으로 저하됩니다.

위의 다단계 예측의 특성이 갖는 리스크 때문에 초기 실험은 t+1을 종속변수로 설정하여 진행하였습니다.

2-2. t+1 모델링
사용 모델
1. `ElasticNet`
   -  빠르고 해석 가능한 선형 모델로 데이터가 선형적으로 얼마나 예측이 가능한지 확인
   -  문제의 기본적인 예측 가능성 타진
   -  회귀 계수를 통해 피처의 영향력을 직관적으로 확인 가능
2. `RandomForestRegressor`
   - 안정적 앙상블 모델, 성능 기준점 설정
   - 데이터의 기본적인 비선형 관계를 잡기 위함

### 사용 피처

### **정적 피처**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `STEEL_TYPE` | 강종 | `원본 메타데이터 값` |
| `SIZE` | 강철바 사이즈 | `원본 메타데이터 값` |
| `LINE_SPEED` | 검사 속도 | `원본 메타데이터 값`|
| `BAR_datetime` | 날짜와 검사 시간 | `원본 메타데이터 값` |

*생성이유*: 정적 피처는 각 검사의 가장 기본적인 환경 정보를 나타내며 특히 `STEEL_TYPE`과 `SIZE`는 LOT 단위로 변경되며 신호의 기준선에 큰 영향을 미치기 때문에, 추후에 모델에 입력을 했을 때 모델이 LOT별로 각기 다른 검사 환경을 구분하고 이해하는데 필요한 정보가 될 것입니다.  
    
### **내부 신호 피처**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `sensor_mean` | 채널 신호값의 평균 | `df['sensor_col'].mean()` |
| `sensor_std` | 채널 신호값의 표준편차 | `df['sensor_col'].std()` |
| `sensor_median` | 채널 신호값의 중위수 | `df['sensor_col'].median()`|
| `event_count_h` | 강철바의 High_level 결함 총 발생 횟수 | `df[h_envnt_col].sum()` |
| `event_count_l` | 강철바의 Law_level 결함 총 발생 횟수 | `df[l_envnt_col].sum()` |
| `sensor_peak_count` | 신호가 상단 임계값을 넘어선 횟수(피크 발생 횟수) | `(signal_original > upper_band_aligned).sum()` |

*생성이유*: 내부 신호 피처는 하나의 강철바를 통과하는 전체 신호의 분포 특성을 평균, 표준편차, 중위수 등의 하나의 통계 값으로 요약을 합니다. 해당 통계값들은 신호의 전반적인 수준과 안정성을 나타냅니다. 결함 발생 횟수와 피크 값 피처는 모델에게 순간적으로 튀는 값의 빈도를 알려줄 수 있습니다. 

### **미시적 시계열 rolling 파생변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `micro_sensor_rolling_std_mean_12` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=12 | `df[sensor_col].rolling(window=12, min_periods=1).std().mean()` |
| `micro_sensor_rolling_mean_std_12` | 채널별 신호값의 이동 평균을 표준편차로 집계, window=12 | `df[sensor_col].rolling(window=12, min_periods=1).mean().std()` |
| `micro_sensor_rolling_std_std_12` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=12 | `df[sensor_col].rolling(window=12, min_periods=1).std().std()` |
| `micro_sensor_rolling_std_mean_49` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=49 | `df[sensor_col].rolling(window=49, min_periods=1).std().mean()` |
| `micro_sensor_rolling_mean_std_49` | 채널별 신호값의 이동 평균을 표준편차로 집계, window=49 | `df[sensor_col].rolling(window=49, min_periods=1).mean().std()` |
| `micro_sensor_rolling_std_std_49` | 채널별 신호값의 이동 표준편차를 표준편차로 집계, window=49 | `df[sensor_col].rolling(window=49, min_periods=1).std().std()` |

*생성이유*: EDA과정에서 하나의 강철바 내부의 신호값을 나타내는 시각화 그래프에서 확인을 했듯이, 강철바 내부의 신호는 변동성이 큽니다. rolling 파생 변수는 window를 이동시키면서 통계량을 계산하여, 단순한 통계값으로는 알 수 없는 신호의 국소적인 변화와 변동성을 포착합니다. 또한 `std().mean()`, `mean().std()`, `std().std()` 를 사용하여 이중으로 집계를 하면서 단순 변동성이 아닌 변동성의 변화 양상이라는 정보들을 모델에게 알려주고자 하였습니다. window_size의 경우에는 12와 49로 나누어 단기적 변화를 모두 학습하도록 설계하였습니다. 

### **미시적 시계열 ewm 파생변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `micro_sensor_ewm_12_mean` | 채널별 신호값의 지수가중평균의 최종값, span=12 | `df[sensor_col].ewm(span=12, min_periods=1).mean().iloc[-1]` |
| `micro_sensor_ewm_12_std` | 채널별 신호값을 지수가중표준편차의 최종값, span=12 | `df[sensor_col].ewm(span=12, min_periods=1).std().iloc[-1]` |
| `micro_sensor_ewm_49_mean` | 채널별 신호값을 지수가중평균의 최종값, span=49 | `df[sensor_col].ewm(span=49, min_periods=1).mean().iloc[-1]` |
| `micro_sensor_ewm_49_std` | 채널별 신호값을 지수가중표준편차의 최종값, span=49 | `df[sensor_col].ewm(span=49, min_periods=1).std().iloc[-1]` |

*생성이유*: rolling은 과거 데이터에 동일한 가중치를 부여하지만, ewm은 최신 데이터에 더 큰 가중치를 줍니다. `iloc[-1]`을 통해 ewm 시계열의 최종값을 추출을 했던 이유는 가중값이 최대한 반영이된 최종 상태 값을 포착하기 위함이였습니다. 이는 강철바의 전반적인 상태를 하나의 값으로 효과적으로 요약하는 전략이 될 수 있습니다. 

2-3. 1차 모델링: 정적 피처 + 내부 신호 피처

1번 타자 모델링
- 가설: 내부 신호 피처와 정적 피처를 통해 대략적인 선형관계를 모델이 잡아낼 수 있을 것 이다.  
- 피처: 정적 피처 + 내부 신호 피처
- 알고리즘: `ElasticNet`
- 모델 파라미터: `alpha: 0.1, l1_ratio: 0.5`
- 평가지표:
  - `r2_score: -0.2304`
  - `mae: 0.0181`
  - `mse: 0.0006`
- 결론: 결정계수가 약 -0.2를 보이면서, 현재 피처들로는 데이터의 패턴을 선형적으로 설명할 수 없음을 확인했습니다. 해당 결과는 단순히 피처의 부족으로 인한 문제일 수도 있겠지만, 데이터가 가진 복잡한 비선형 관계를 선형 모델이 포착하지 못하는 한계일 가능성이라는 것 또한 있다고 생각을 했습니다. 따라서 다음 실험은 동일한 피처를 사용하면서, 비선형 관계를 학습할 수 있는 트리 기반 모델을 사용하여 가설을 검증해보기로 했습니다.

2번 타자 모델링
- 가설: 1번 타자 모델링과 피처셋은 동일하나 선형 모델에서 비선형 모델로 바뀌었기 때문에 모델이 데이터의 비선형 관계를 학습하여 기본적인 예측값을 뱉어낼 것 같다.
- 피처: 정적 피처 + 내부 신호 피처
- 알고리즘: `RandomForestRegressor`
- 모델 파라미터: X
- 평가지표:
  - `r2_score: -0.0785`
  - `mae: 0.0177`
  - `mse: 0.0007`
- 결론: 피처는 이전 실험과 동일하게 하여, 모델만 회귀 계수 모델에서 트리 기반 모델로 변경하여 예측을 시도해 보았으나, 여전히 결정계수가 음수를 띄면서 기존의 정적 피처와 기본 통계 값들이 대부분인 내부 신호 피처들로는 예측이 불가능하다는 결론을 내리게 되었습니다.
다음 실험은 추가적인 미시적인 시계열 파생변수들을 추가하여 진행합니다.

2-3. 2차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생변수 + 미시적 ewm 파생변수

1번 타자 모델링
- 가설: 미시적인 rolling 파생변수와 미시적인 ewm 파생변수가로 모델이 데이터에서 선형적인 관계를 잡아내면서 예측이 될 거 같다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생변수 + 미시적 ewm 파생변수
- 알고리즘: `ElasticNet`
- 파라미터: `alpha: 0.1, l1_ratio: 0.5`
- 평가지표:
  - `정확한 수치들은 유실되었으나 결정계수가 여전히 음수를 보였음`
- 결론: 실험노트를 작성하는 과정에서 `ElasticNet` 모델링 평가지표에 대한 정확한 점수는 유실되었지만 결정계수가 여전히 음수를 띄었습니다. 해당 시계열 회귀 예측 문제는 피처의 양만으로는 해결되지 않는 비선형성을 가지고 있음을 확인하여 추가적으로 진행되는 모든 모델링 실험에서는 선형 모델을 완전히 배제하고 비선형 관계 학습에 강점을 가진 트리 기반 모델만을 사용하기로 결정하였습니다.

2번 타자 모델링
- 가설: 시적인 rolling 파생변수와 미시적인 ewm 파생변수가로 선형 모델이 잡아내지 못했던 비선형적인 관계를 트리 모델이 학습을 하여 예측에 성능을 보일 것 같다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생변수 + 미시적 ewm 파생변수
- 알고리즘: `RandomForesetRegressor `
- 파라미터: X
- 평가지표:
  - `r2_score: 0.6861`
  - `mae: 0.0093`
  - `mse: 0.0001`
- 시계열 교차검증:
  - `Fold 1/5: R²: 0.6203, MAE: 0.0106, MSE: 0.0004`
  - `Fold 2/5: R²: 0.8725, MAE: 0.0071, MSE: 0.0001`
  - `Fold 3/5: R²: 0.6785, MAE: 0.0082, MSE: 0.0001`
  - `Fold 4/5: R²: 0.8074, MAE: 0.0076, MSE: 0.0001`
  - `Fold 5/5: R²: 0.6215, MAE: 0.0092, MSE: 0.0001`
  - `Average: R²: 0.7200 (+/- 0.1022), MAE: 0.0085 (+/- 0.0013), MSE: 0.0002 (+/- 0.0001)`
- 결론: `RandomForesetRegressor `로 예측을 한 초기 모델링의 평가지표는 예상과 다르게 이전 보다 매우 높게 측정이 되어 누수가 발생을 했는지 확인을 해보기 위해 5개의 폴드로 나눠 폴드가 누적이 되는 방식으로 시계열 교차검증을 진행을 하여 평가지표를 뽑아 보았는데 폴드마다 약간의 편차를 보이기는 하지만 여전히 점수가 나오는 것을 확인 했습니다. 또한 결정계수 뿐만 아니라 평균 절대 오차 값 또한 종속변수의 평균값(0.0745)을 고려했을 때 꽤 높게 나온 점 또한 눈여겨 볼만합니다.
미시적인 rolling, ewm 파생변수가 강력한 변수인 것임은 예상은 했지만 예상과 다르게 과하다 싶을 정도의 점수가 나와 추가적인 검증이 필요할 것으로 보입니다.
종속변수가 `t+1`인 바로 다음 시퀀스를 예측하는 것이기 때문에 현재 시점인 `t`와의 강력한 자기 상관 또한 의심을 하게 되는 계기가 되었습니다.

3번 타자 모델링
- 가설: 시적인 rolling 파생변수와 미시적인 ewm 파생변수가로 `RandomForesetRegressor`보다 성능이 뛰어 나다고 알려진 `XGBoostRegressor`를 사용하여 얼마나 더 높은 점수를 보이는지 확인하면서, 해당 모델링의 결과에 상관없이 종속변수의 재설정 검토가 필요할 듯함.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생변수 + 미시적 ewm 파생변수
- 알고리즘: `XGBoostRegressor`
- 평가지표:
  - `r2_score: 0.6674`
  - `mae: 0.0097`
  - `mse: 0.0001`
- 시계열 교차검증:
  - `Fold 1/5: R²: 0.3209, MAE: 0.0116, MSE: 0.0007`
  - `Fold 2/5: R²: 0.8628, MAE: 0.0073, MSE: 0.0001`
  - `Fold 3/5: R²: 0.6586, MAE: 0.0082, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7944, MAE: 0.0080, MSE: 0.0001`
  - `Fold 5/5: R²: 0.5788, MAE: 0.0097, MSE: 0.0002`
  - `Average: R²: 0.6431 (+/- 0.1894), 0.0090 (+/- 0.0015), 0.0002 (+/- 0.0002)`
- 피처 중요도
<img width="1106" height="682" alt="XGB1" src="https://github.com/user-attachments/assets/c0e1dbc5-9011-4d2d-bf47-6e9148624e3d" />


- SHAP value
<img width="803" height="940" alt="XGB2" src="https://github.com/user-attachments/assets/9a875da4-4e01-4f83-a8bb-38049020ebb0" />


결론: 분명 `XGBoostRegressor`가 `RandomForesetRegressor` 보다 더 높은 평가지표 점수를 반환해 낼 것이라고 가설을 설정하고 모델링 실험을 진행하였지만, 예상과 다르게 `RandomForesetRegressor`의 점수를 넘지 못했습니다. 해당 실험을 통해 `XGBoostRegressor`가 항상 뛰어난 성능을 보장한다는 것은 아님을 알 수 있었으며, 새롭게 `XGBoostRegressor`의 피처 중요도와 SHAP value 시각화 그래포 또한 뽑아 보았는데, 제일 처음의 정적인 피처와 내부 신호값으로만 모델링을 진행을 했을 때는 해당 피처들로는 예측이 불가능 하다는 결론을 내렸지만 미시적인 rolling, ewm 파생변수를 투입을 하고 보니 기존의 기본적인 통계값들이 중요도 부분에서 제일 상위 부분에 위치하는 것을 확인 할 수 있었습니다. 이는 새롭게 추가된 미시적 파생 변수들이 단독으로 강력한 예측력을 가졌다기보다, 기존의 기본 통계 피처들과 상호작용하며 그 피처들이 가진 포텐을 끌어내는 역할을 했음을 의미합니다. 이 분석을 통해, 단순히 개별적인 중요도가 낮은 피처라도 다른 변수와의 상호작용 관계 속에서 피처의 중요도가 향상이 될 수 있음을 확인했습니다.


## 3. 문제 정의의 진화, t+10 시점 신호값 회귀 예측 모델링 실험

3-1. 종속변수 설정 근거

프로젝트 초기에는 t+1 시점의 노이즈를 예측하는 것을 목표로 설정했습니다. 하지만 높은 예측 성능에도 불구하고, 문제 정의 자체에 대한 근본적인 의문을 가지게 되어 자기상관성 분석을 수행했습니다.
<img width="1389" height="989" alt="image" src="https://github.com/user-attachments/assets/80e0caba-fc6a-40b7-a885-72c2e80cf605" />
<ACF와 PACF 그래프>

자기 상관성 분석 결과, ACF는 매우 완만하게 감소하고 PACF는 Lag 1에서 급격히 절단되는 패턴이 확인 되었습니다.이는 종속 변수가 강력한 추세와 자기상관성을 가지면서, 특히 현재 값`t`이 바로 다음 값인 `t+1`을 예측하는 데 결정적인 정보임을 의미합니다. 즉, `t+1` 예측은 모델의 성능이나 피처가 뛰어나다기 보다는, 문제 자체가 가진 특성으로 인해 모델이 풀기 쉬운 문제였던 것이라고 결론을 내릴 수 있겠습니다. 

이러한 단기 예측은 실질적인 비즈니스 가치를 제공하기 어렵다고 판단을 하여, 프로젝트의 목표를 단순 예측을 넘어 이보다 더 의미 있는 사전 경고 시스템을 구축하는 방향으로 재정의를 하기로 했습니다. 이에 따라 종속 변수를 `t+1`에서 더 먼 미래인 `t+10`으로 전환을 하였습니다. `t+10`을 타겟으로 설정함으로써, 모델이 단순히 바로 직전 시점 `t`의 값을 복사하는 쉬운 학습과 예측을 하는 것을 방지하고, 데이터에 내재된 더 복잡하고 장기적인 패턴을 학습하도록 유도하는 효과도 있습니다 앞서 설명드린 다단계 예측이 갖는 리스크에도 불구하고 `t+10`을 종속 변수로 선택한 이유는, 예측 성공 시 실제 공정에서 `t+1`에 비해 압도적으로 긴 대응 시간을 확보하여 실질적인 예지 보전의 가능성을 열 수 있기 때문입니다. 

종속변수 특성
- `df['sensor_A1_y'].mean() = 0.0745` 종속변수의 평균 값의 경우 전체 채널의 종속 변수 평균과 A1 센서의 종속변수 평균 값은 소수점 4자리 수 까지는 값이 같습니다. 
- 해당 실험은 우선적으로 10개의 센서중 A1의 센서를 대상으로 실험을 진행하였습니다.
- `t+1` 실험은 전체 채널의 평균을 종속변수로 하여 예측을 진행을 했으며, 해당 실험에서는 CH_B3 센서의 중위수 통계 값이 가장 높은 피처로 선정이 되었음에도 불구하고 CH_A1의 값을 종속 변수로 선택을 한 이유는, 강철바가 검사 센서로 들어올 때 신호값의 변동이 일어나게 되는데(예를 들어 아래로 흐르는 물에 손가락을 넣게 되면 물이 튀게 되는 것과 같이 말이죠.), 이때 강철바와 가장 먼저 조우를 하게 되는 센서가 1숫자를 가진 센서입니다. 따라서 이러한 점을 고려하여 A1 센서를 타겟으로 설정을 하게되었습니다. 
- 종속변수가 `right_skew` 형태를 띄어 로그 변환을 해주어 실험을 진행하였습니다. 원래 `right_skew` 형태를 띈다고 해서 무조건적으로 로그변환을 해야하는 것은 아니지만, 두 변수를 따로 해서 실험을 진행하였을 때 로그변환된 종속변수를 대상으로 실험을 했을 때 예측 성능이 더 좋게 나와서 로그 변환을 하여 계속 실험을 진행하기로 하였습니다. 
<img width="1589" height="616" alt="image" src="https://github.com/user-attachments/assets/1a8c78cf-551f-4cae-8e9d-683bb5a82654" />
<로그변환 전(왼쪽)과 로그 변환 후(오른쪽)의 그래프>

3-2. 실험 계획
아래는 `t+10` 모델링 실험에 대한 계획입니다.
1. 단일 채널 우선 검증
   - 팀의 최종 목표는 모든 채널에 대한 예측 모델 개발이지만, 신속한 반복 실험과 가설 검증을 위해 우선 대표 채널 하나(sensor_A1)를 선정했습니다. 해당 단일 채널에 모든 방법론을 적용하여 모든 피처셋과 최적의 모델링을 선정한 이후 이를 나머지 채널로 확장하는 접근법을 선택했습니다.
  
2. 점진적 피처 엔지니어링
   - 피처가 추가가 될 때마다 모델의 성능이 얼마나 향상이 되는지를 검증하기 위하여, 기존의 피처셋에서 미시적, 거시적 시계열 피처 그룹을 순차적으로 추가하며 각 단계별로 성능의 변화를 측정하고 기록합니다.
  
3. 모델 전략
   - 비선형 모델 집중: 초기 `t+1` 실험에서 선형 모델의 한계를 확인했기 때문에, `t+1`에 비해 난이도가 더욱 향상된 `t+10` 예측에서는 비선형 관계 학습에 장점을 가진 트리 기반 모델만을 사용합니다.
   - XGBoost 우선 탐색: 초기 피처의 상호작용을 파악하기 위해 특정 중요 피처에 집중하는 `LightGBM`보다 다양한 피처를 비교적 균일하게 활용하는 `XGBoost`를 우선적으로 사용합니다.

4. 최종 모델 선정
   - Optuna를 사용한 하이퍼파라미터 최적화를 통해 `XGBoost`와 `LightGBM`의 성능을 극한으로 끌어올린 후, 최종적으로 가장 뛰어난 모델을 선정합니다. 선정된 모델을 추후에 10개의 통합된 채널 실험에 적용합니다.

3-3. 사용피처

### **정적 피처**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `STEEL_TYPE` | 강종 | `원본 메타데이터 값` |
| `SIZE` | 강철바 사이즈 | `원본 메타데이터 값` |
| `LINE_SPEED` | 검사 속도 | `원본 메타데이터 값`|
| `BAR_datetime` | 날짜와 검사 시간 | `원본 메타데이터 값` |

*생성이유*: 정적 피처는 각 검사의 가장 기본적인 환경 정보를 나타내며 특히 `STEEL_TYPE`과 `SIZE`는 LOT 단위로 변경되며 신호의 기준선에 큰 영향을 미치기 때문에, 추후에 모델에 입력을 했을 때 모델이 LOT별로 각기 다른 검사 환경을 구분하고 이해하는데 필요한 정보가 될 것입니다.  

### **내부 신호 피처**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `sensor_mean` | 채널 신호값의 평균 | `df['sensor_col'].mean()` |
| `sensor_std` | 채널 신호값의 표준편차 | `df['sensor_col'].std()` |
| `sensor_median` | 채널 신호값의 중위수 | `df['sensor_col'].median()`|
| `event_count_h` | 강철바의 High_level 결함 총 발생 횟수 | `df[h_envnt_col].sum()` |
| `event_count_l` | 강철바의 Law_level 결함 총 발생 횟수 | `df[l_envnt_col].sum()` |
| `sensor_peak_count` | 신호가 상단 임계값을 넘어선 횟수(피크 발생 횟수) | `(signal_original > upper_band_aligned).sum()` |

*생성이유*: 내부 신호 피처는 하나의 강철바를 통과하는 전체 신호의 분포 특성을 평균, 표준편차, 중위수 등의 하나의 통계 값으로 요약을 합니다. 해당 통계값들은 신호의 전반적인 수준과 안정성을 나타냅니다. 결함 발생 횟수와 피크 값 피처는 모델에게 순간적으로 튀는 값의 빈도를 알려줄 수 있습니다. 

### **미시적 시계열 rolling 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `micro_sensor_rolling_std_mean_11` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=11 | `df[sensor_col].rolling(window=11, min_periods=1).std().mean()` |
| `micro_sensor_rolling_mean_std_11` | 채널별 신호값의 이동 평균을 표준편차로 집계, window=11 | `df[sensor_col].rolling(window=11, min_periods=1).mean().std()` |
| `micro_sensor_rolling_std_std_11` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=11 | `df[sensor_col].rolling(window=11, min_periods=1).std().std()` |
| `micro_sensor_rolling_std_mean_33` | 채널별 신호값의 이동 표준편차를 평균으로 집계, window=33 | `df[sensor_col].rolling(window=33, min_periods=1).std().mean()` |
| `micro_sensor_rolling_mean_std_33` | 채널별 신호값의 이동 평균을 표준편차로 집계, window=33 | `df[sensor_col].rolling(window=33, min_periods=1).mean().std()` |
| `micro_sensor_rolling_std_std_33` | 채널별 신호값의 이동 표준편차를 표준편차로 집계, window=33 | `df[sensor_col].rolling(window=33, min_periods=1).std().std()` |
| :--- | :--- | :--- |
| `micro_sensor_rolling_min_mean_11` | 채널별 신호값의 이동 최솟값을 평균으로 집계, window=11 | `df[sensor_col].rolling(window=11, min_periods=1).min().mean()` | 
| `micro_sensor_rolling_min_std_11` | 채널별 신호값의 이동 최솟값을 표준편차로 집계, window=11 | `df[sensor_col].rolling(window=11, min_periods=1).min().std()` | 
| `micro_sensor_rolling_min_mean_33` | 채널별 신호값의 이동 최솟값을 평균으로 집계, window=33 | `df[sensor_col].rolling(window=33, min_periods=1).min().mean()` |
| `micro_sensor_rolling_min_std_33` | 채널별 신호값의 이동 최솟값을 표준편차로 집계, window=33 | `df[sensor_col].rolling(window=33, min_periods=1).min().std()` | 

*생성이유*: `t+1` 실험과 마찬가지로, EDA에서 확인된 원본 신호의 높은 변동성을 완화하고 신호의 국소적인 변화를 포착하기 위해 사용했습니다. 다만 실험을 통해 최적의 성능을 보인 window_size를 11과 33으로 변경하였습니다. 또한 단일 채널을 대상으로 하는 실험에서는 사용되지 않았지만, 전 피처를 대상으로 하는 실험에는 미시적인 최솟값 관련 피처들이 추가가 됐습니다. 내부 신호의 최솟값을 이동 평균과 이동 평균으로 집계를 한 피처를 생성하였습니다. 특히 `micro_sensor_rolling_mean_33` 피처의 경우 종속변수와 가장 유사한 로직으로 계산된 피처이며, 종속변수를 예측을 하는데 있어 가장 많은 정보를 제공할 것으로 추측을 해봅니다.  

### **미시적 시계열 ewm 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `micro_sensor_ewm_11_mean` | 채널별 신호값의 지수가중평균의 최종값, span=11 | `df[sensor_col].ewm(span=11, min_periods=1).mean().iloc[-1]` |
| `micro_sensor_ewm_11_std` | 채널별 신호값을 지수가중표준편차의 최종값, span=11 | `df[sensor_col].ewm(span=11, min_periods=1).std().iloc[-1]` |
| `micro_sensor_ewm_33_mean` | 채널별 신호값을 지수가중평균의 최종값, span=33 | `df[sensor_col].ewm(span=33, min_periods=1).mean().iloc[-1]` |
| `micro_sensor_ewm_33_std` | 채널별 신호값을 지수가중표준편차의 최종값, span=33 | `df[sensor_col].ewm(span=33, min_periods=1).std().iloc[-1]` |

*생성이유*: `t+1` 실험과 동일하게, 최신 데이터에 더 큰 가중치를 부여하여 강철바의 최종 상태를 효과적으로 요약하기 위해 ewm 피처를 사용했습니다. rolling과 마찬가지로, span_size를 11과 33으로 변경하여 적용했습니다.

### **미시적 순열 엔트로피 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
`sensor_col_perm_entropy` | 채널별 신호값의 순열 엔트로피(복잡도) | `ant.perm_entropy(df[sensor_col], normalize=True)` |

*생성이유*: amtropy 라이브러리의 순열 엔트로피(perm_entropy) 알고리즘을 사용하였으며, 순열 엔트로피는 시계열 데이터의 순서 관계를 기반으로 패턴의 무작위성 즉, 신호의 복잡성 또는 예측 불가능성을 측정하기 위해 사용합니다. 표준편차가 단순히 신호의 크기가 얼마나 변동하는지를 본다면, 순열 엔트로피는 신호의 패턴이 얼마나 무질서한지를 봅니다. 데이터의 값이 아닌, 값의 상대적인 순서에 주목하기 때문에 신호의 잡음에 강하다는 장점이 있습니다.
원래는 오리지널 entropy 알고리즘을 사용하려 하였으나 계산 시간이 너무 오래 걸려서 이보다 훨씬 가벼운 순열 엔트로피로 대체를 하게 되었습니다.

### **미시적 카츠 프랙탈 차원 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `sensor_col_katz_fd` | 채널별 신호값의 카츠 프랙탈 차원(거칠기) | `ant.katz_fd(df[sensor_col])` |

*생성이유*: antropy 라이브러리의 카츠 프랙탈 차원(Katz Fractal Dimension) 알고리즘을 사용하였으며, 엔트로피와는 다른 관점에서, 신호의 기하학적인 거칠기를 측정하기 위해 사용합니다. 프랙탈 차원은 선형적인 통게량으로는 포착하기 힘든 신호의 복잡한 형태를 숫자로 나타냅니다. 

### **거시적 lag 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `col_lag_1` | 채널별 기본 통계값에 shift(1) 적용 | `df.groupby(['LOT_ID'])[col].shift(1)` |
| `col_lag_3` | 채널별 기본 통계값에 shift(3) 적용 | `df.groupby(['LOT_ID'])[col].shift(3)` |
| `col_lag_5` | 채널별 기본 통계값에 shift(5) 적용 | `df.groupby(['LOT_ID'])[col].shift(5)` |
| `col_lag_9` | 채널별 기본 통계값에 shift(9) 적용 | `df.groupby(['LOT_ID'])[col].shift(9)` |

*생성이유*: lag는 시계열 데이터의 핵심 특성인 자기 상관관계를 모델에게 학습시키기 위한 피처입니다. 머신러닝 모델은 각 행을 독립적인 데이터로 간주하므로, `shift()`함수를 사용하여 과거 시점의 값을 새로운 피처로 추가함으로써 데이터의 시간 의존성을 주입합니다. lag가 적용되는 값은 이전에 산출했던 평균, 표준편차, 중위수 즉, 기본통계값에 적용합니다. 

### **거시적 rolling 파생 변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `macro_col_rolling_mean_3` | 채널별 기본 통계값에 적용하는 이동 평균, window=3 | `df.groupby(['LOT_ID'])[col].rolling(window=3).mean()` |
| `macro_col_rolling_mean_11` | 채널별 기본 통계값에 적용하는 이동 평균, window=11 | `df.groupby(['LOT_ID'])[col].rolling(window=11).mean()` |
| `macro_col_rolling_std_3` | 채널별 기본 통계값에 적용하는 이동 표준편차, window=3 | `df.groupby(['LOT_ID'])[col].rolling(window=3).std()` |
| `macro_col_rolling_std_11` | 채널별 기본 통계값에 적용하는 이동 표준편차, window=11 | `df.groupby(['LOT_ID'])[col].rolling(window=11).std()` |

*생성이유*: EDA에서 확인을 했듯, 해당 데이터 프레임은 LOT 단위로 신호 패턴과 강종 등이 완전히 리셋이 되는 구조를 가집니다. 거시적 rolling 파생 변수는 LOT 내부에서 기본 통계 피처들의 시간에 따른 추세를 포착하기 위해 설계되었습니다. 이동평균 기법은 특정 크기window를 이동시키며 통계량을 계산하여, 단기적인 노이즈를 완화하고 데이터의 국소적인 흐름을 보여주는 가장 기본적인 방법입니다. window 크기를 3과 11로 설정한 것은, 모델에게 매우 짧은 기간의 즉각적인 추세(window=3)와조금 더 안정적인 중기적 추세(window=11)를 모두 제공하기 위함입니다. 

### **거시적 ewm 파생변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `macro_col_ewm_mean_3` | 채널별 기본 통계값에 적용하는 지수 이동 평균 | `df.groupby(['LOT_ID'])[col].ewm(span=3).mean()` |
| `macro_col_ewm_mean_11` | 채널별 기본 통계값에 적용하는 지수 이동 평균 | `df.groupby(['LOT_ID'])[col].ewm(span=11).mean()` |
| `macro_col_ewm_std_3` | 채널별 기본 통계값에 적용하는 지수 이동 표준편차 | `df.groupby(['LOT_ID'])[col].ewm(span=3).std()` |
| `macro_col_ewm_std_11` | 채널별 기본 통계값에 적용하는 지수 이동 표준편차 | `df.groupby(['LOT_ID'])[col].ewm(span=11).std()` |

*생성이유*: EDA에서 확인을 했듯, 해당 데이터 프레임은 LOT 단위로 신호 패턴과 강종 등이 완전히 리셋이 되는 구조를 가집니다. 거시적 ewm 파생 변수는 이러한 구조를 고려하여, 각 LOT 내부에서 기본 통계 피처들이 시간의 흐름에 따라 어떻게 변하는지 그 추세를 모델에게 알려주기 위해 설계가 되었습니다. ewm은 최신 강철바 데이터에 더 큰 가중치를 부여하기 때문에, 장비의 점진적인 상태 악화와 같은 변화 현상을 모델에 알려줄 수 있습니다.
span 값은 단기적이고 민감한 추세와 중기적이고 안정적인 추세를 제공하기 위해 설정되었습니다. 

### **거시적 LOT내부 컨텍스트 파생변수**
| Feature | Description | Calculation Method / Example |
| :--- | :--- | :--- |
| `bar_in_lot_sequence` | LOT 내에서 강철바의 상대적인 순서 | `df.groupby('LOT_ID').cumcount() + 1` |
| `normalized_sequence` | LOT내부 시간 정규화 | `(df['bar_in_lot_sequence'] - 1) / (df.groupby('LOT_ID')['bar_in_lot_sequence'].transform('max') - 1)` |
| `noise_delta_from_start` | LOT 시작점 대비 노이즈의 절대적 변화량 | `df[micro_sensor_rolling_std_mean_11] - df.groupby('LOT_ID')[noise_col].transform('first')` |
| `noise_ratio_from_start` | LOT 시작점 대비 노이즈의 상대적 변화율 | `df[micro_sensor_rolling_std_mean_11] / (start_noise + 1e-6)` |
| `seq_x_volatility` | 시간에 따라 가중된 변동성 | `df[bar_in_lot_sequence] * df[micro_sensor_rolling_std_mean_11]` |

*생성이유*: EDA에서 확인을 했듯, 해당 데이터 프레임은 LOT 단위로 신호 패턴과 강종 등이 완전히 리셋이 되는 구조를 가집니다. LOT 내부 컨텍스트 피처 그룹은 모델이 단순히 개별 강철바만 보는 것이 아닌, 해당 강철바가 소속된 LOT내에서 초반, 중반, 후반 중 어디쯤 위치해 있는가라는 맥락을 모델이 이해하도록 돕습니다. 또한 변동관련 피처들의 변동값들을 계산하기 위해서 `micro_sensor_rolling_std_mean_11`을 선택한 이유는 해당 컬림은 이동 표준편차의 평균으로 해당 강철바의 신호가 평균적으로 얼마나 흔들렸는가를 나타내는 즉, 신호의 국소적인 변동성과 불안정성을 가장 잘 나타내는 지표이기 때문이기 때문입니다.


3-4. 1차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수

1번 타자 모델링
- 가설: 피처로는 미시적 시계열 rolling 파생변수가 추가가된 가운데, 문제의 난이도는 `t+1`에 비해 더 어려워진 상황에서 결정계수가 0에 가까운 양수를 띄게 될 것이다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수
- 알고리즘: `RandomForestRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.2956`
  - `mae: 0.0112`
  - `mse: 0.0001`
- 결론: 너무 낮지도 높지도 않은 이상적인 결정계수 값과 비교적 높은 평균절대 오차가 나왔습니다. 이는 앞으로 추가되는 피처에 따라서 개선될 여지가 있는 굉장히 반가운 점수입니다.

2번 타자 모델링
- 가설: `RandomForestRegressor`에 비해 근소하게 높은 점수를 보일 것이다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
   - `r2_score: 0.3572`
   - `mae: 0.0102`
   - `mse: 0.0001`
- 피처 중요도
<img width="677" height="551" alt="XGB3" src="https://github.com/user-attachments/assets/170a68e5-a3d5-47e2-96cd-00ce326d0f26" />

- SHAP value
<img width="551" height="677" alt="XGB4" src="https://github.com/user-attachments/assets/7d27c00d-ea31-4582-96f9-35e05c7c42f5" />

- 결론: `XGBoostRegressor`는 가설대로 `RandomForestRegressor`에 비해 근소한 성능 향상(`R²: 0.29 -> 0.35`, `mae: 0.0112 -> 0.0102`)을 보였습니다. 모델의 성능에 큰 괴리가 없어 별도의 교차검증 없이 다음 단계로 진행했으며, `XGBoost` 모델의 피처 중요도와 `SHAP value`를 통해 다음과 같은 핵심 인사이트를 얻었습니다.
1. 피처 중요도 그래프를 봤을 때 가장 흥미로운 점은, 타겟 채널 그러니까 종속변수가 CH-A1의 신호값임에도 불구하고, CH-A1의 중앙값보다 바로 옆에 위치한 전방 센서 CH-A2의 중앙 값이 더 높은 피처 중요도 점수를 기록했다는 점입니다. 이는 단순하게 인접한 센서의 정보가 중요하다는 것을 넘어 강철바가 검사 센서에 처음 진입할 때 발생하는 신호의 변화를 모델이 강력한 예측 근거로 학습을 했음을 추측해 볼 수 있습니다. 여기서 말하는 신호의 변화는 단순히 급변하는 단발성 피크 값을 의미하는 것이 아닌, 안정 상태에 있던 센서가 강철바라는 새로운 객체를 감지하며 발생하는 신호의 전반적인 레벨과 패턴의 변화를 의미합니다. 따라서 해당 신호의 변화를 감지하는 것은 전방에 위치한 센서들이 되게 될 것이며, 모델이 해당 신호 값의 변화를 측정한 센서에 중요도를 두어 학습을 하고 있다는 것을 추측해 볼 수 있습니다. 
2. 새롭게 추가된 미시적 rolling 기반의 파생 변수들 보다, 기본 통계 피처 중 중앙값의 중요도가 월등히 높게 나타났습니다. 중앙값은 다른 통계 값들인 평균과 표준편차에 비하여 이상치에 덜 민감한 특성을 갖는데, 이는 모델이 순간적으로 튀는 피크 값들과 같이 변동성이 큰 값들 보다 강철바의 전반적으로 안정된 신호 레벨을 예측의 강한 근거로 사용하고 있음을 추측해 볼 수 있습니다.
3. `SHAP value` 분석 결과, 피처 중요도에서는  CH-A2의 중앙 값이 더 높은 피처 중요도 점수를 기록하였지만, 영향력 부분에서는 CH-A1의 중앙값 피처가 더 높게 나타났습니다. 이는 모델의 전체적인 예측 구조를 만드는 데는 `CH-A2_median` 피처가 가장 많은 기여를 하였지만, 실제 예측값 하나하나를 결정하는 데는 `CH_A1_median` 피처가 더 강한 영향력을 발휘했다고 해석을 할 수 있습니디. 정적 피처들 중 `size`와 특정 강종의 피처들 또한 예측에 상당한 영향을 미치는 것으로 보입니다. 아직 `size`피처의 경우 긍정적인 영향인지 부정적인 영향을 주는지에 대해서는 정확하게 파악이 어렵지만, 이는 추가적으로 추가되는 피처에 따라 일어 나는 상호작용 여부에 따라 더 정확히 알 수 있을 것 같습니다.

3-5. 2차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수

1번 타자 모델링
- 가설: 강력한 미시적 ewm 파생변수가 추가가 되었기 때문에 모든 평가지표 점수에서 무조건적인 점수 향상이 예상됨.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수
- 알고리즘: `RandomForestRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.3420`
  - `mae: 0.0108`
  - `mse: 0.0001`
- 결론: 근소한 점수 향상(`R²: 0.29 -> 0.34`, `mae: 0.0112 -> mae: 0.0108`) 생각과는 다르게 점수 향상 폭이 작았습니다.

2번 타자 모델링
- 가설: 앞서 `RandomForestRegressor` 모델링 실험으로 확인한 바와 같이 ewm 파생 변수의 추가가 모델 성능에 미치는 성능 개선은 여전히 미미할 것으로 예상하지만, 해당 모델링의 핵심은 피처 중요도 순위 변화를 관찰하는 것에 있습니다. 미시적 ewm 피처는 `.iloc[-1]` 로직을 통해 강철바가 검사 센서를 빠져나가는 시점의 최종 상태를 나타냅니다. 이 최종 상태는 최근 데이터 즉, 후반부 데이터에 가중치를 주어 산출이된 값입니다. 이는 이전 모델이 강철바의 초기 진입 상태를 중요하게 학습을 했던 것과 대조적인 부분입니다. 따라서 이번 실험에서는 후방에 위치한 4또는 5의 센서 피처들의 중요도가 상승하여 순위에 변동이 있을 것이라고 예상을 합니다.
- 피처: 적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.4491`
  - `mae: 0.0096`
  - `mse: 0.0001`
- 시계열 교차검증
  - `Fold 1/5: R²: 0.6568, MAE: 0.0094, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7731, MAE: 0.0082, MSE: 0.0002`
  - `Fold 3/5: R²: 0.4772, MAE: 0.0082, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7112, MAE: 0.0086, MSE: 0.0001`
  - `Fold 5/5: R²: 0.2941, MAE: 0.0084, MSE: 0.0001`
  - `Average: R²: 0.5825 (+/- 0.1748),  MAE: 0.0086 (+/- 0.0005), MSE: 0.0002 (+/- 0.0000)`
- 피처 중요도
<img width="677" height="551" alt="XGB5" src="https://github.com/user-attachments/assets/f3c17de0-262c-40ab-a8d5-264c8417ce9b" />

- SHAP value
<img width="551" height="677" alt="XGB6" src="https://github.com/user-attachments/assets/8e33cccc-bcbc-4f22-9d85-9dffb060ba8d" />

- 결론: 평가지표 점수만을 놓고 봤을 때는 `RandomForestRegressor`에 비해서 점수 향상 폭이 더 크지만, 이후 추가적인 시계열 교차 검증에서 폴드마다 점수의 변동이 큰 것을 확인 할 수 있습니다. 특히나 모든 폴드의 데이터가 누적이 되어 가장 많은 데이터로 학습 및 예측을 진행하는 5번째의 폴드에서 결정계수가 다른 폴드들에 비해서 매우 낮게 나온 것을 확인을 할 수 있습니다. 평균 절대 오차 값의 경우는 데이터의 개수가 가장적은 첫 번째 폴드에서 가장 높게 나타났습니다. 이는 아마 정보의 부족이 낳은 결과인 것으로 추측을 해볼 수 있겠습니다.
1. 가설에서 설정했던 후방 센서 관련 피처들의 중요도 순위 상승을 기대했으나, `CH_B4_median` 값만이 3번째로 높은 피처로 나타났고 다른 후방 센서들은 이전 모델링과 비교를 했을 때와 크게 변화된 부분은 없었습니다. 아마 모델이 여전히 강철바가 처음에 들어올 때 나타나는 신호값을 빠져날 때 신호값 보다 더 중요도를 두고 학습을 하는 것으로 보여집니다.
2. 또한 새롭게 추가된 미시적 ewm 피처들은 중요도 부분에서 높은 순위를 기록하지 못했지만, SHAP 분석 결과, 이전 모델에서는 파악할 수 없었던 `num_size` 피처가 미시적 ewm 피처 추가 이후 예측에 부정적인 영향을 미치기 시작하는 상호작용을 발견했습니다. 이는 미시적 ewm 피처가 단독으로 작용을 하기 보다는 다른 피처들의 영향력을 변화시키는 역할을 하고 있음을 의미하며, 추후 피처 선택시 고려해야할 점이 되겠습니다.

3-6. 3차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수

1번 타자 모델링
- 가설: 처음으로 추가되는 거시적 관점의 파생변수입니다. 거시적이라는 새로운 관점의 정보를 모델에게 주는 만큼 당연한 점수 향상을 예상합니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수
- 알고리즘: `RandomForestRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5038`
  - `mae: 0.0093`
  - `mse: 0.0001`
- 결론: 실험 이후로 가장 비약적인 점수 향상이 이루어졌습니다. 결정계수 부분에서 굉장한 점수 향상이 있었습니다. 이제 미시적인 피처와 거시적인 피처를 투입했을 때 `RandomForestRegressor`로 피처가 점수 향상에 기여를 하는 것을 알게 되었으니, 다음에 있을 실험 부터는 `XGBoost`모델만을 단독으로 사용하여 성능 개선을 확인합니다.

2번 타자 모델링
- 가설: 이전 실험에서는 미시적인 파생변수들만 추가를 했었지만, 처음으로 거시적 관점의 파생변수를 추가하게 되었는데, 거시적인 관점이라고는 하지만 기본 통계값을 대상으로 적용해서 산출해낸 과거값 파생변수이기 때문에 기존의 기본 통계값 피처들의 중요도가 더 향상될 것이라고 예상을 함과 동시에 모델에게 다양한 과거 시점의 자기 상관 정보를 알려주게 됨으로써 비약적인 점수 향상이 예상됩니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5142`
  - `mae: 0.0091`
  - `mse: 0.0001`
- 시계열 교차 검증:
  - `Fold 1/5: R²: 0.7401, MAE: 0.0086, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7817, MAE: 0.0080, MSE: 0.0002`
  - `Fold 3/5: R²: 0.5720, MAE: 0.0074, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7381, MAE: 0.0080, MSE: 0.0001`
  - `Fold 5/5: R²: 0.3527, MAE: 0.0082, MSE: 0.0001`
  - `Average: R²: 0.6369 (+/- 0.1593), MAE: 0.0080 (+/- 0.0004), MSE: 0.0001 (+/- 0.0000)`
- 피처 중요도
<img width="677" height="551" alt="XGB7" src="https://github.com/user-attachments/assets/70c3f779-083c-4843-abe9-c1f2f1e69711" />

- SHAP value
<img width="551" height="677" alt="XGB8" src="https://github.com/user-attachments/assets/369e6071-13b6-4eae-a311-68bd6079e52b" />

- 결론: 단일 평가지표나 5개의 폴드를 봤을 때 전체적으로 점수 부분에서 향상이 있었습니다. 또한 특정 폴드에서는 결정계수가 0.78을 넘어가면서 모델의 상당히 높은 설명력을 나타내고 있습니다. 그러나 여전히 데이터를 가장 많이 가지고 예측을 하는 5번째 폴드에서 가장 낮은 결정계수 점수를 기록하였습니다.
1. 피처 중요도 그래프를 봤을 때 가장 눈에 띄는 점은 이전의 미시적 rolling 파생 변수들이 차지하고 있던 자리들을 거시적 lag 파생 변수들이 전부 밀어낸 것을 확인할 수 있습니다. 주로 가까운 과거값들의 lag 파생변수들이 중요도 부분에서 높은 순위에 위치하고 있는데, 이는 가까운 과거일수록 자기 상관이 강한 특성이 미래 예측에 있어서 중요한 정보를 제공하는 것임을 확인할 수 있습니다.  
2. SHAP value 부분에서는 lag 파생 변수들이 몇 추가가 된 것을 제외하고는 크게 눈에 띄는 변화는 없습니다.


3-7. 4차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수
- 가설: 두 번째 거시적 관점에서 설계된 피처의 추가입니다. LOT 내 강철바의 기본 통계값들의 단기적, 중기적 추세에 대한 정보를 모델에 주게 될텐데, 해당 정보를 통해 모델이 예측을 진행했을 때, 5번째 폴드의 다른 폴드에 비해 압도적으로 낮은 결정계수의 격차가 어느 정도 완화될 것이라고 예상을 해봅니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생변수 + 미시적 ewm 파생변수 + 거시적 lag 파생변수 + 거시적 rolling 파생변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5195`
  - `mae: 0.0091`
  - `mse: 0.0001`
- 시계열 교차 검증:
  - `Fold 1/5: R²: 0.7344, MAE: 0.0088, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7778, MAE: 0.0080, MSE: 0.0002`
  - `Fold 3/5: R²: 0.5683, MAE: 0.0075, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7408, MAE: 0.0080, MSE: 0.0001`
  - `Fold 5/5: R²: 0.4339, MAE: 0.0076, MSE: 0.0001`
  - `Average: R²: 0.6511 (+/- 0.1304), MAE: 0.0080 (+/- 0.0005), MSE: 0.0001 (+/- 0.0000)`
- 피처 중요도:
<img width="677" height="551" alt="XGB9" src="https://github.com/user-attachments/assets/ae02fd47-feed-4f4a-9d38-570fff4d7006" />

- SHAP value:
<img width="551" height="677" alt="XGB10" src="https://github.com/user-attachments/assets/25ea9540-c730-4891-b7be-4e73a06a4f87" />

- 결론: 가설에서 예상했듯이, 거시적 rolling 피처는 전체적인 성능 향상 폭은 작았지만(`R²: 0.63 -> 0.65`, `mae`의 경우 향상 X), 가장 성능이 낮았던 5번째 폴드의 R² 점수를 0.35에서 0.43으로 끌어올리며 다른 폴드와의 격차를 줄임과 동시에 모델의 안정성을 개선하는 데 성공했습니다. 이는 LOT 내부의 기본 통계값의 단기적, 중기적 추세 정보가, 예측이 어려웠던 특정 구간의 성능을 보완하는 데 긍정적인 역할을 했음을 의미합니다.
1. 피처 중요도 그래프를 보면 기본 중위수값, 거시적 lag 파생변수, 특정 강종 피처, 거시적 rolling 파생변수들이 골고루 분포해 있지만 미시적인 파생변수는 거의 보이지 않습니다. 이는 `t+10`과 같이 상대적으로 먼 미래를 예측하는 문제에서는, 강철바 내부의 신호 패턴(미시적)보다, 여러 강철바에 걸친 전반적인 추세와 맥락(거시적)이 훨씬 더 중요한 정보로 작용한다는 것을 보여줍니다.
2.  SHAP value 부분에서는 거시적 rolling 파생 변수들이 몇 추가가 된 것을 제외하고는 크게 눈에 띄는 변화는 없습니다.


3-8. 5차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수
- 가설: 이전 실험에서 거시적 rolling 파생 변수의 추가를 통해서 모델의 가장 큰 약점이였던, 5번째 폴드의 결정 계수를 다른 폴드들의 결정 계수와 격차를 줄이는데 성공하였습니다. 이는 LOT 내부의 추세 정보가 모델의 안정성 개선에 기여를 하는 것을 알 수 있습니다.
이번에 추가하는 거시적 ewm 피처들은 단순 rolling 피처들과 달리 최신 데이터에 더 큰 가중치를 부여하여 변화를 감지하는 추세 정보를 담고 있습니다. 따라서, ewm 피처가 rolling 피처 또한 불안정한 5번째 폴드의 결정 계수 점수를 개선할 수 있을 것이라고 예상을 합니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5394`
  - `mae: 0.0087`
  - `mse: 0.0001`
- 시계열 교차 검증:
  - `Fold 1/5: R²: 0.7370, MAE: 0.0089, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7772, MAE: 0.0081, MSE: 0.0002`
  - `Fold 3/5: R²: 0.5317, MAE: 0.0079, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7593, MAE: 0.0077, MSE: 0.0001`
  - `Fold 5/5: R²: 0.3272, MAE: 0.0084, MSE: 0.0001`
  - `Average: R²: 0.6265 (+/- 0.1739), MAE: 0.0082 (+/- 0.0004), MSE: 0.0001 (+/- 0.0000)`
- 피처 중요도:
<img width="677" height="551" alt="XGB11" src="https://github.com/user-attachments/assets/2823afee-3231-441f-91e9-5c3de3f61a9e" />

- SHAP value:
<img width="551" height="677" alt="XGB12" src="https://github.com/user-attachments/assets/20c53ea9-4963-4d49-9ff7-a1fed17efa19" />

- 결론: 거시적 ewm 파생 변수가 5번째 폴드의 결정 계수의 향상에 기여를 해줄 것이라는 가설을 비웃듯 거시적 ewm 피처 추가 이후 모델의 전체적인 성능은 오히려 하락(`R²: 0.65 -> 0.62`)했으며, 저희의 가장 큰 문제이자 숙제였던 5번째 폴드의 결정 계수는 0.43에서 0.32로 대폭 하락했습니다. 하지만 피처 중요도를 봤을 때 놀라운 반전이 나타났습니다. 성능 저하의 원인일 것으로 생각을 했던 거시적 ewm 피처들이 오히려 중요도에서 최상위권을 모두 차지한 것입니다.
1. 피처 중요도에서 거시적 ewm 피처들이 다른 피처들을 몰아내고 최상위권을 독식한 것은 모델이 거시적 ewm 피처에 과도하게 의존 그러니까 과적합되어, 데이터의 패턴을 학습하는 성능이 저하되었을 것이라고 의심하게 합니다. 특히 거시적 ewm 피처 중에서도 표준편차로 집계한 피처들 보다 평균으로 집계한 피처들의 중요도가 압도적으로 높은 것은, 모델이 LOT 내의 '최신 평균 추세라는 정보에 매몰된 것을 의심해 볼 수 있겠습니다.
2. 거시적 ewm 피처 추가 이후, 이전 모델에서 늘 최상위에 있던 A 채널의 전방 센서의 중위수 피처들의 중요도가 크게 하락했습니다. 이는 새롭게 추가된 거시적 ewm 피처들이 피처 간의 복잡한 상호작용이 낳은 부정적인 결과라고 해석을 할 수 있습니다.
3. 해당 실험은 강력한 피처라고 무조건 추가하는 것이 항상 성능 향상으로 이어지지는 않는다는 굉장히 중요한 정보를 주었습니다. 또한 반대로 성능을 저하시키는 피처라고 해서 함부로 피처를 제거할 수 없는 이유를 알 수 있었던 모델링 실험이였습니다.


3-9. 6차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수 + 거시적 LOT 내부 컨텍스트 파생 변수
- 가설: 마지막 거시적 관점의 파생 변수 추가입니다. LOT 내부의 시간축 정규화 피처를 기반으로 만들어진 파생 변수들이지만 10개의 채널 별로 계산이 되어 수십개씩 생성이 되는 다른 파생 변수들에 비해 개수가 상당히 적어(5개) 거시적 ewm 파생 변수가 망쳐놓은 성능을 개선할 수 있을지는 미지수입니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수 + 거시적 LOT 내부 컨텍스트 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가 지표:
  - `r2_score: 0.5744`
  - `mae: 0.0081`
  - `mse: 0.0001`
- 시계열 교차 검증:
  - `Fold 1/5: R²: 0.7461, MAE: 0.0089, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7821, MAE: 0.0080, MSE: 0.0002`
  - `Fold 3/5: R²: 0.5582, MAE: 0.0077, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7545, MAE: 0.0078, MSE: 0.0001`
  - `Fold 5/5: R²: 0.4010, MAE: 0.0077, MSE: 0.0001`
  - `Average: R²: 0.6484 (+/- 0.1470), 0.0080 (+/- 0.0004), 0.0001 (+/- 0.0000)`
- 피처 중요도:
<img width="677" height="551" alt="XGB13" src="https://github.com/user-attachments/assets/68bd2645-7f59-4c0e-ad7d-62ed6217fa0e" />

- SAHP value:
<img width="551" height="677" alt="XGB14" src="https://github.com/user-attachments/assets/a0169f09-0c6b-4f8d-b9f9-7accfa2f9e8c" />

- 결론: 수백개의 파생 변수가 추가가 된 가운데, 5개의 새로운 거시적 내부 컨텍스트 파생 변수가 성능 개선에 성공했습니다. 단일 평가 지표에서 모든 점수가 향상(`R²: 0.62 -> 0.64, MAE: 0.0087 -> MAE: 0.0081`)된 것은 물론이고, 시계열 교차 검증에서 또한 대부분의 폴드에서 성능 개선이 이루어졌으며, 특히 5번째 폴드에서 점수가 크게 개선이 되었습니다(`R²: 0.32 -> 0.40,  MAE: 0.0084 -> MAE: 0.0077`). 5개의 피처로 이런 성능 개선을 이루어냈다는 것이 놀랍습니다. 해당 실험 결과는 수백 개의 미시적/거시적 피처 속에서, `bar_in_lot_sequence`(LOT내 순서)를 기반으로 생성된 파생 변수들이 얼마나 강한 영향을 가질 수 있는지를 알 수 있습니다. 피처 중요도와 SHAP value에서는 기존의 ewm 피처들이 여전히 상위권을 차지하고 있어 큰 변화는 없었지만, 해당 거시적 컨텍스트 피처들이 모델의 전반적인 예측 안정성을 보완해 준 것으로 해석할 수 있습니다. 이번 실험은 단순히 피처의 개수를 늘리기보다 도메인 지식을 바탕으로 생성한 상호작용 피처 설계가 중요하다는 점을 보여줍니다. `bar_in_lot_sequence * sensor_std`와 같이 시간의 흐름과 변동성을 곱하여 생성하는 등 추가적인 상호작용 피처를 설계했다면 더 높은 성능 개선을 기대할 수 있었을 것이라는 점은 아쉬운 부분으로 남습니다.

3-10. 7차 모델링: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수 + 거시적 LOT 내부 컨텍스트 파생 변수 + 미시적 순열 엔트로피 파생 변수 + 미시적 카츠 프랙탈 차원 파생 변수 
1번 타자 모델링
- 가설: 미시적 파생 변수의 추가 실험이 끝과 동시에 CH-A1에 대한 피처 추가 실험도 끝이나게 됩니다. 더 이상의 파생 변수의 추가는 없습니다. 마지막으로 투입되는 변수는 `antropy` 라이브러리의 순열 엔트로피 파생 변수와 카츠 프랙탈 차원 파생 변수입니다. 해당 파생 변수들은 미시적인 관점에서 각각 내부 신호의 불안정성과 복잡도를 피처로 담아낸 기존 피처들과는 다른 정보를 줄 수 있는 피처들이지만, 피처 중요도나 영향력 부분에서 미시적인 파생 변수들 보다 거시적인 파생 변수들이 상위 부분을 거의 차지 하고 있었던 것을 이전 실험들을 통해서 확인을 할 수 있었습니다. 따라서 뚜렷한 점수 향상을 기대하기는 어려울 것으로 예상이 됩니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수 + 거시적 LOT 내부 컨텍스트 파생 변수 + 미시적 순열 엔트로피 파생 변수 + 미시적 카츠 프랙탈 차원 파생 변수
- 알고리즘: `XGBoostRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5623`
  - `mae: 0.0084`
  - `mse: 0.0001`
- 시계열 교차 검증
  - `Fold 1/5: R²: 0.7399, MAE: 0.0088, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7911, MAE: 0.0079, MSE: 0.0002`
  - `Fold 3/5: R²: 0.5273, MAE: 0.0079, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7548, MAE: 0.0078, MSE: 0.0001`
  - `Fold 5/5: R²: 0.3459, MAE: 0.0082, MSE: 0.0001`
  - `Average: R²: 0.6318 (+/- 0.1702), MAE: 0.0081 (+/- 0.0003), MSE: 0.0001 (+/- 0.0000)`
- 피처 중요도
<img width="677" height="551" alt="image" src="https://github.com/user-attachments/assets/91e314ba-7cbd-4575-99ac-54512356df45" />

- SHAP value
<img width="551" height="677" alt="image" src="https://github.com/user-attachments/assets/485474da-5044-40f7-9e3c-892d58876366" />

-결론: 미시적 엔트로피 파생 변수들을 추가하더라도 평가 지표 점수가 크게 향상이 될 것이라고 예상을 하지는 않았으나, 전체적으로 평가지표 점수가 떨어지는 결과를 얻었습니다. 특히 해당 실험의 숙제인 5번째 폴드에서 크게 점수가 떨어졌습니다(`R²: 0.4010 -> 0.3459`, `MAE: 0.0077 -> 0.0082`). 피처 중요도나 SHAP value 그래프는 이전 실험과 크게 다른점은 없는 거 같습니다.

2번 타자 모델링
- 가설: 해당 실험은 `XGBoost` 알고리즘만 사용을 하는 것이 아닌 `LGBM` 알고리즘까지 사용을 하면서 모든 파생 변수들이 추가가된 시점에서 두 모델의 성능을 비교해보는 식으로 실험 진행이 되겠습니다. 이전 `XGBoost`에서 끊임없이 약점을 보였던 5번째 폴드에서 `LGBM`이 보다 더 나은 성능을 보일 것이라고 예상을 해봅니다.
- 피처: 정적 피처 + 내부 신호 피처 + 미시적 rolling 파생 변수 + 미시적 ewm 파생 변수 + 거시적 lag 파생 변수 + 거시적 rolling 파생 변수 + 거시적 ewm 파생 변수 + 거시적 LOT 내부 컨텍스트 파생 변수 + 미시적 순열 엔트로피 파생 변수 + 미시적 카츠 프랙탈 차원 파생 변수
- 알고리즘: `LightGBMRegressor`
- 파라미터: `n_jobs=-1`(모든 CPU 코어 사용)
- 평가지표:
  - `r2_score: 0.5679`
  - `mae: 0.0084`
  - `mse: 0.0001`
- 시계열 교차 검증
  - `Fold 1/5: R²: 0.7690, MAE: 0.0085, MSE: 0.0002`
  - `Fold 2/5: R²: 0.7911, MAE: 0.0078, MSE: 0.0002`
  - `Fold 3/5: R²: 0.6070, MAE: 0.0072, MSE: 0.0001`
  - `Fold 4/5: R²: 0.7830, MAE: 0.0074, MSE: 0.0001`
  - `Fold 5/5: R²: 0.3747, MAE: 0.0081, MSE: 0.0001`
  - `Average R²: 0.6649 (+/- 0.1602), MAE: 0.0078 (+/- 0.0005), MSE: 0.0001 (+/- 0.0000)`
- 피처 중요도:
<img width="677" height="551" alt="image" src="https://github.com/user-attachments/assets/480e220a-9dfa-4b8d-b5b4-2b05561acc3d" />

- SHAP value:
<img width="551" height="677" alt="image" src="https://github.com/user-attachments/assets/6ef3f33d-4c5f-4364-a3f8-503c5af4e739" />

결론: 결론부터 말하자면 `LGBM`이 `XGBoost` 모델 보다 성능이 더 뛰어났습니다(`LGBM:Average R²: 0.6649 (+/- 0.1602), MAE: 0.0078 (+/- 0.0005), XGB: R²: 0.6318 (+/- 0.1702), MAE: 0.0081 (+/- 0.0003`). 평균 절대 오차의 경우 `XGBoost`에서 미세하게 적은 편차를 보였으나, 결정계수에서는 `LGBM` 의 편차가 약 0.01 정도 더 낮았습니다. 해당 비교는 별도의 파라미터 튜닝이 적용이 되지 않은 상태에서의 비교입니다. 따라서 이후에 추가적으로 파라미터 최적화 실험을 통해서 최종 모델을 선정하여 최종 실험인 10개의 센서에 적용을 할 예정입니다. 
1. 피처 중요도 부분에서 두 모델의 피처 중요도를 봤을 때 굉장히 흥미로웠습니다. `XGBoost`의 경우에는 여전히 ewm으로 계산된 중위수 파생 변수들이 중요도 최상위를 차지했지만, `LGBM`의 경우는 파생 변수도 아니고 기본적인 `size` 즉, 원형 강종의 둘레를 나타내는 컬림이 최상위에 위치한 것과 또 내부 컨텍스트 파생 변수들이 상뒤에 분포하는 것을 확인할 수 있었습니다. 이는 `LGBM` 이 `XGBoost` 보다 LOT 내부에서 일어나는 맥락을 더 중요한 정보로 판단하고 학습했음을 추측해볼 수 있습니다. 이 결과는 동일한 문제라도 모델에 따라 문제 해결 방법을 찾는 경로가 다를 수 있음을 보여줍니다.

3-11. 하이퍼 파라미터 튜닝 이후 최종 알고리즘 선정
옵투나 서치를 통해서 결정 계수가 가장 높게 나오는 파라미터를 선정하여 최종적으로 두 모델의 성능을 비교해봅니다.

1. XGBoost 파라미터 튜닝 결과
-  **hyperparameters** = 
   `{'n_estimators': 110,` 
   `'max_depth': 8,` 
   `'learning_rate': 0.20176037377739728,` 
   `'subsample': 0.7393547249717748,` 
   `'colsample_bytree': 0.8398758931149709,` 
   `'gamma': 0.004290609621850017,` 
   `'min_child_weight': 10}`
- 평가지표:
  - `R²: 0.3954`
  - `MAE: 0.0079`
  - `MSE: 0.0001`
 
2. LGBM 파라미터 튜닝 결과
-  **hyperparameters** = 
   `{'n_estimators': 799,`
   `'max_depth': 3,` 
   `'learning_rate': 0.14535662131531957,` 
   `'num_leaves': 201,` 
   `'subsample': 0.7127409133303556,` 
   `'colsample_bytree': 0.873969242517182,` 
   `'reg_alpha': 0.6052781767573712,` 
   `'reg_lambda': 0.9149586567111028}`
- 평가지표:
  - `R²: 0.4894`
  - `MAE: 0.0072`
  - `MSE: 0.0001`
 
결론: 하이퍼파라미터 튜닝 결과, 모든 평가지표에서 `LGBM`이 `XGBoost`를 앞서며 최종 모델로 선정되었습니다(LGBM: `R²: 0.4894, MAE: 0.0072`, XGBoost: `R²: 0.3954, MAE: 0.0079`). 하지만, 튜닝 이후의 결정 계수 점수(`R²: 0.49`)가 튜닝 전(`R²: 0.66`)보다 오히려 낮게 나타나는 결과가 나왔습니다. 이는 옵투나 최적화 과정에서 발생한 코드 오류로 인해, 각 모델의 절대적인 최적 파라미터를 찾는 데에는 실패했습니다. 하지만, 동일하게 편향된 조건 하에서도 `LGBM`이 `XGBoost`를 모든 지표에서 압도하는 결과를 보였습니다. 이는 특정 파라미터 값을 떠나, LGBM 알고리즘 자체가 본 문제에 더 적합함을 증명하는 결과입니다. 따라서 재튜닝 과정은 생략하고, `LGBM`을 최종 알고리즘으로 선택하였습니다.

## 4. 최종 모델 검증: 전체 채널 확장 적용

지금까지 진행됐던 실험은 하나의 대표 채널을 대상으로, 다양한 관점에서 생성된 파생 변수가 모델에 어떻게 성능을 개선을 하는지와 최종실험에 적합한 알고리즘을 찾아가는 과정으로 진행이 되었습니다. 해당 장에서는, 앞에서 추가한 파생 변수들을 10개의 채널을 대상으로 적용하여 평균을 내서 피처 중요도로 순위를 매긴 이후에 엘보우 기법으로 찾아낸 최적의 피처 개수에 맞춰서 피처 제거 및 10개의 채널을 대상으로 글로벌 파라미터 최적화를 진행하여 줍니다. 

4-1. 실험 계획
아래는 글로벌 채널 대상 모델링 실험에 대한 계획입니다.
1. 500개가 넘는 피처에서 전체 채널을 대상으로 글로벌 피처 순위 매기기를 진행합니다.
2. 엘보우 기법을 통해서 전체 채널을 대상으로 최적의 피처 개수를 찾아냅니다.
3. 옵투나를 통해서 전체 채널을 대상으로 최적의 파라미터를 구합니다.
4. 모든 값을 적용하여 모델링을 하여 평가지표를 산출해 냅니다. 

4-2. 엘보우 기법으로 찾은 최적의 피처 개수

<img width="857" height="545" alt="image" src="https://github.com/user-attachments/assets/739b6854-a07f-4d05-91cc-5071243cd2d1" />

엘보우 기법으로 찾아낸 최적의 피처의 개수는 100개입니다. 500개가 넘는 기존의 피처 개수를 생각하면 400개가 넘는 피처를 제거해줘야 되는 부분입니다.

4-3. 글로벌 피처 기준 TOP 100 피처

- 글로벌 파라미터 피처 중요도 top 100
<img width="1111" height="3333" alt="global1" src="https://github.com/user-attachments/assets/f3267825-9329-4b52-822a-0c9d05991268" />

- SHAP value
<img width="793" height="10000" alt="global2" src="https://github.com/user-attachments/assets/eedc1b62-bb18-4b3e-896f-5fd445128cf8" />

글로벌 피처 중요도와 SHAP value 그래프에 대한 해석
1. 피처 중요도 그래프: 10개의 모든 채널을 대상으로 엘보우 기법으로 찾아낸 중요한 피처 top 100개를 선정했습니다. 해당 피처들은 10개의 채널에 공통적으로 이용이 될 것입니다. 피처 중요도 그래프를 봤을 때 가장 높은 순위를 차지를 한 피처는 `size` 피처입니다. 다른 피처들에 비해서 압도적인 수치를 보였으며, 뒤를 이어서 A, B 채널들의 거시적 ewm 피처들이 뒤를 이었습니다. 여기서 최상단 부분에 거시적이 아닌 미시적 `micro_rolling_min_mean_33` 피처들이 상위 부분을 차지한 것을 확인할 수 있습니다. 해당 피처는 단일 채널을 대상으로 실험을 할 때는 추가를 하지 않았다가 팀원들과 여러 논의 끝에 선정한 종속변수의 신호값이 채널의 미시적 이동 최솟값의 평균(window=30)임을 고려했을 때 가장 자기상관이 높은 피처이기 때문에 종속변수 기준 lag의 역할을 하는 해당 피처가 미시적인 피처임에도 불구하고 중요도 부분에서 높은 순위를 기록을 했던 것을 알 수 있습니다. 이는 모델이 수백 개의 피처 속에서 종속변수와 가장 강한 자기상관성을 가진 핵심 피처를 성공적으로 찾아 냈다고 해석을 할 수 있겠습니다. 또한, 이전 단일 채널 실험에서는 크게 주목을 받지 못했던 앤트로피 라이브러리 기반 피처인 순열 엔트로피 피처들이 피처 중요도 상위권에 다수 등장한 것은, 모델이 전체 채널의 맥락을 학습하게 되면서 비로소 신호의 불안정성 같은 내부 신호의 질적인 정보를 예측에 있어 중요한 피처로 사용했다는 것을 알 수 있습니다.  
2. SHAP value 그래프: 중요도 그래프와 다르게 SHAP value 그래프를 보면 `micro_rolling_min_mean_11`, `micro_rolling_min_mean_33` 피처들이 상위 부분을 차지하였습니다. 앞서 말한 것과 같이 종속변수 로직과 가장 유사하며 피처 자체에 강한 자기상관 특성이 있기 때문에 모델이 종속변수를 예측함에 있어 가장 영향을 많이 받는 피처인 것을 확인할 수 있습니다. 

4-4. 10개 채널의 평균 성능을 최적화하는 파라미터
 **hyperparameters** = 
`{'n_estimators': 417, 
  'learning_rate': 0.026471834394199895, 
  'num_leaves': 31, 
  'max_depth': 3, 
  'subsample': 0.7156675682552961, 
  'colsample_bytree': 0.7001372474318698}`

글로벌 파라미터 최적화 분석 결과
- 글로벌 파라미터 튜닝 실험에서는 모델의 구조와 학습률에 더 직접적인 영향을 미치는 `n_estimators, num_leaves, learning_rate`와 같은 핵심 파라미터에 집중을 하고 `reg_alpha`와 `reg_lambda` 같은 규제 파라미터들은 기본값을 사용하기로 결정을 하였습니다. 의도한 것은 아니지만 이전에 단일 채널에서 진행을 했던 파라미터 튜닝에서, 5개 폴드 중 가장 데이터가 적은 5개의 폴드 중 1번 폴드만을 기준으로 최적화를 진행을 했습니다. 해당 실험에서 얻은 파라미터를 보면 `n_estimators`, `learning_rate`, `num_leaves`에서 상당한 차이를 보입니다.
1. `n_estimators`의 차이. 단일 채널을 대상으로 진행이 됐던 실험에서의 `LGBM`의 `n_estimators` 즉, 트리의 개수에서 약 2배 가량의 차이를 보입니다. 트리의 개수를 크게 지정할수록 예측 성능이 높아질 수 있으나, 너무 크게 지정하면 오히려 과적합으로 성능이 저하 될 수 있는 위험이 있습니다. 
2. `learning_rate`의 차이. 학습 속 또한 단일 채널에서의 값이 0.14로 글로벌 파라미터의 값인 0.02보다 더 높게 나왔습니다. 학습률이 0.14 또한 그리 높은 값은 아니지만 학습률이 높을 때는 모델이 빠르게 학습을 할 수 있지만 중요한 데이터를 놓칠 수 있다는 위험이 있고, 학습률이 낮을 때는 모델이 신중하게 학습을 하여 좋은 결과를 낼 수 있지만, 시간이 오래 걸립니다. 
3. `num_leaves`의 차이. 하나의 트리가 가질 수 있는 최대 리프 개수로, 해당 파라미터 또한 단일 채널에서 201로 값이 더 높게 나왔으며 글로벌 파라미터의 값은 디폴드 값인 31이 그대로 나왔습니다.

- 결론적으로 전에 진행했던 단일 채널 실험에서 1번 폴더라는 적은 개수의 데이터 + 500개가 넘는 피처의 개수의 특성상 과적합이 일어날 수 있는 환경에서 얻어진 파라미터를 적용했을 때 낮은 결정계수 값이 나왔습니다. 이는 모델이 복잡도인 `num_leaves` 와 학습 속도인 
`learning_rate`를 높여 특정 데이터에 대한 예측 성능만 극대화했기 때문에 과적합이 나왔다고 판단을 할 수 있습니다. 반면 글로벌 튜닝으로 도출된 파라미터는 10개 채널과 5개의 폴드 전체에서 성능을 해야하기 때문에 낮은 `num_leaves`와 낮은 `learning_rate`로 최적화 되었습니다.

<글로벌 피처와 최적화된 파라미터를 적용한 모델링의 결정 계수표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.8151 | 0.8293 | 0.8488 | 0.8111 | 0.8107 | 0.7939 | 0.8117 | 0.8261 | 0.7949 | 0.7803 |
| 2 | 0.8656 | 0.8612 | 0.8609 | 0.8657 | 0.8977 | 0.8508 | 0.8535 | 0.8515 | 0.8772 | 0.8792 |
| 3 | 0.6753 | 0.7575 | 0.7588 | 0.7925 | 0.7916 | 0.5834 | 0.6305 | 0.3282 | 0.7019 | 0.7377 |
| 4 | 0.8254 | 0.7821 | 0.6403 | 0.7937 | 0.7448 | 0.7828 | 0.7874 | 0.7805 | 0.7912 | 0.8344 |
| 5 | 0.5994 | 0.5794 | 0.2760 | 0.6292 | 0.6110 | 0.5668 | 0.6272 | 0.1053 | 0.5605 | 0.5276 |

<img width="1590" height="889" alt="image" src="https://github.com/user-attachments/assets/dfd05cc9-73da-420d-a485-e245b265a7ef" />

글로벌 피처 TOP 100 피처와 최적화된 파라미터를 적용하여 얻은 폴드별 결정계수에 대한 해석
- 모든 채널과 폴드별로 똑같은 가중치를 주어 결정 계수의 평균을 내보면 `R²= 0.728 ± 0.160` 의 결과 값이 나옵니다. 이는 모델이 상당한 설명력을 갖는다고 해석을 할 수 있지만, 폴드별로 분석을 진행을 해본다면 세번째 폴드와 5번째 폴드에서 약점을 보인다는 것을 알 수 있습니다. 특히 5번째 폴드는 이전 실험에서도 계속 똑같은 문제점으로 거론이 됐었던 폴더이며 결정계수가 가장 높은 폴더와 상당한 편차를 가집니다. 또한 모든 채널을 기준으로 봤을 때 5번째 폴드의 결정 계수들이 낮긴하나 그래도 대부분의 채널에서는 결정 계수값을 0.5를 넘겼으며 심지어 0.6을 넘기는 채널도 있었습니다만, A 채널의 3번째 센서와 B 채널의 3번째 센서의 결정계수를 보면 각각 0.2760, 0.1053으로 다른 채널의 5번째 폴드들에 비해 상당히 낮은 값들을 갖습니다. 두 센서의 공통점으로는 둘다 3번째 채널이라는 점이며, 다른 채널들과 비교를 했을 때 압도적으로 낮은 수치를 봤을 때 센서의 물리적인 문제가 있을 것이라고 추측을 해볼 수 있습니다. 이는 모델이 단순히 미래 신호 값을 예측하는 것을 넘어서 어떤 센서와 어떤 기간에 문제가 발생하는지 진단하는 근거로 활용될 수 있는 가치 또한 지닐 수 있습니다. 추가로 5번째 폴드 성능 개선을 위해서 모델이 최근 데이터에 가중치를 두고 학습을 하게 하는  `model.fit(X_train, y_train, sample_weight=sample_weights)` 옵션을 사용하였습니다. 5번째 폴드에서 추가되는 데이터는 미래와 가장 가까운 데이터며 가장 최근 데이터이기도 하기 때문에 최근 데이터에 가중치를 두는 옵션인 `sample_weight`를 사용하였으나, 성능 개선에는 실패를 하였으며, 이는 문제의 원인이 단순한 시간적 가중치로 해결될 수 없는 요인이 있음을 보여줍니다. 

<글로벌 피처와 최적화된 파라미터를 적용한 모델링의 평균 절대 오차표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.0074 | 0.0071 | 0.0062 | 0.0069 | 0.0063 | 0.0073 | 0.0074 | 0.0066 | 0.0067 | 0.0077 |
| 2 | 0.0062 | 0.0061 | 0.0062 | 0.0062 | 0.0051 | 0.0058 | 0.0060 | 0.0058 | 0.0055 | 0.0052 |
| 3 | 0.0064 | 0.0064 | 0.0058 | 0.0059 | 0.0072 | 0.0072 | 0.0071 | 0.0068 | 0.0057 | 0.0064 |
| 4 | 0.0066 | 0.0082 | 0.0063 | 0.0062 | 0.0077 | 0.0065 | 0.0068 | 0.0063 | 0.0067 | 0.0067 |
| 5 | 0.0061 | 0.0068 | 0.0063 | 0.0063 | 0.0063 | 0.0060 | 0.0056 | 0.0064 | 0.0072 | 0.0068 |

<img width="1589" height="889" alt="image" src="https://github.com/user-attachments/assets/d5f60c17-5d69-490b-ad70-94f4ffd4e77d" />

글로벌 피처 TOP 100 피처와 최적화된 파라미터를 적용하여 얻은 폴드별 평균 절대 오차에 대한 해석
- 평균 절대 오차의 그래프를 보면 결정 계수의 점수가 가장 좋은 2번째 폴드에서 오차 값 또한 가장 낮게(좋게) 나타납니다. 이를 봤을 때 "결정 계수와 평균 절대 오차값은 반비례 하나?"라고 생각을 할 수도 있겠지만, 결정계수의 값이 2번째로 높았던 4번째 폴드의 평균 절대 오차값이 가장 높게(안좋게) 나타나는 것을 봤을 때 결정 계수의 점수가 높다고 해서 평균 절대 오차 값이 꼭 낮은 것은 아니다라는 것을 알 수 있습니다. 결정 계수의 점수가 가장 낮은 5번째 폴드 또한 평균 절대 오차 값을 봤을 때 다른 채널들에 비해 크게 떨어지지 않는 것 또한 확인할 수 있습니다. 해당 표에 대한 분석은 하나의 평가지표에 매몰되지 않고, 다각적으로 여러 평가지표를 분석 하면서 모델의 약점을 파악하는 것이 왜 중요한지를 보여줍니다. 

## 5. 특잇값 분해와 주성분 분석

특잇값 분해 
<img width="1590" height="1189" alt="image" src="https://github.com/user-attachments/assets/e335ec7b-1bc9-427c-8bcf-f9b884665876" />

그래프 해석
1. Linear Scale 그래프: 첫 번째 그래프를 보면 10개 미민의 소수의 지배적인 특잇값이 데이터 분산의 대부분을 설명하고 있는 것을 확인할 수 있습니다. 이는 600여 개의 피처들 사이에 상당한 정보의 중복성, 즉 다중공선성 문제가 존재함을 시각적으로 보여줍니다. 따라서 PCA와 같은 선형적 차원 축소 기법을 통해 정보의 중복성을 제거하고, 모델의 성능 개선과 함께 취약 폴더 성능 또한 개선을 할 수 있을 것이라는 가설을 세울 수 있습니다.
2. Log Scale 그래프: 두 번째 그래프인 로그 스케일 그래프를 봤을 때 해당 그래프의 긴 꼬리 부분은 데이터에 많은 저강도 정보의 복잡성이 내재되어 있음을 의미합니다. 이것이 단순 선형 변환인 PCA는 대부분의 저강도 정보를 노이즈로 간주하고 제거를 하는 특성을 갖지만 LGBM 모델은 알고리즘 자체가 다중공선성의 영향을 덜 받는 특성도 있지만 저강도 정보 속에서도 의미가 있는 비선형적인 패턴을 찾아 학습할 수 있기 때문에 무작정 피처를 제거하고 보는 행위는 정보 손실을 야기할 수 있는 위험이 있습니다. 

<PCA 적용 모델링과 비교를 위한 피처 제거 없는 600여 개의 피처 모델링의 결정 계수표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.7949 | 0.8140 | 0.8197 | 0.7938 | 0.8151 | 0.7728 | 0.7282 | 0.8245 | 0.7281 | 0.7637 |  
| 2 | 0.8621 | 0.8516 | 0.8517 | 0.8555 | 0.8876 | 0.8474 | 0.8112 | 0.8458 | 0.8795 | 0.8763 |  
| 3 | 0.6723 | 0.7510 | 0.7521 | 0.8555 | 0.7743 | 0.4778 | 0.5069 | 0.3364 | 0.6719 | 0.6482 |  
| 4 | 0.8174 | 0.7578 | 0.6372 | 0.7801 | 0.7333 | 0.7673 | 0.7672 | 0.6719 | 0.7863 | 0.8290 |  
| 5 | 0.5975 | 0.5627 | 0.2655 | 0.6014 | 0.6114 | 0.5116 | 0.5883 | 0.0177 | 0.5030 | 0.4267 |  

<img width="1590" height="889" alt="image" src="https://github.com/user-attachments/assets/47ab65ea-b54a-4d4f-8cc5-6d7ad3566dd5" />

<PCA 적용 모델링과 비교를 위한 피처 제거 없는 600여 개의 피처 모델링의 평균 절대 오차표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.0077 | 0.0074 | 0.0068 | 0.0072 | 0.0065 | 0.0077 | 0.0083 | 0.0067 | 0.0071 | 0.0078 |  
| 2 | 0.0063 | 0.0064 | 0.0066 | 0.0066 | 0.0054 | 0.0060 | 0.0067 | 0.0061 | 0.0056 | 0.0054 |  
| 3 | 0.0065 | 0.0067 | 0.0061 | 0.0061 | 0.0077 | 0.0079 | 0.0082 | 0.0072 | 0.0062 | 0.0073 |  
| 4 | 0.0068 | 0.0087 | 0.0064 | 0.0065 | 0.0080 | 0.0067 | 0.0069 | 0.0076 | 0.0068 | 0.0068 |  
| 5 | 0.0063 | 0.0070 | 0.0064 | 0.0066 | 0.0064 | 0.0064 | 0.0059 | 0.0067 | 0.0077 | 0.0076 |  

<img width="1589" height="889" alt="image" src="https://github.com/user-attachments/assets/c061c306-7c8a-4af1-a111-7c8efa5e0fe7" />

PCA(차원 축소)적용 이후 모델링 평가지표 결과

<각 채널과 폴드마다 데이터의 95% 분산을 설명하는 데 필요한 주성분의 개수>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 | 
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | 94 | 94 | 94 | 94 | 94 | 94 | 94 | 94 | 94 | 94 |
| 2 | 92 | 92 | 92 | 92 | 92 | 92 | 92 | 92 | 92 | 92 |
| 3 | 84 | 84 | 84 | 84 | 84 | 84 | 84 | 84 | 84 | 84 | 
| 4 | 90 | 90 | 90 | 90 | 90 | 90 | 90 | 90 | 90 | 90 | 
| 5 | 101 | 101 | 101 | 101 | 101 | 101 | 101 | 101 | 101 | 101 | 

<맞춤형 차원 축소 적용이후 각 채널과 폴드별 결정계수표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.7226 | 0.7453 | 0.7445 | 0.7709 | 0.7536 | 0.6702 | 0.7036 | 0.7289 | 0.6568 | 0.6603 |  
| 2 | 0.7860 | 0.7799 | 0.7636 | 0.7696 | 0.8231 | 0.8191 | 0.7888 | 0.8179 | 0.8213 | 0.8315 |
| 3 | 0.6000 | 0.6495 | 0.6667 | 0.6831 | 0.6470 | 0.2178 | 0.3122 | 0.2901 | 0.5904 | 0.4500 |
| 4 | 0.7953 | 0.6702 | 0.5859 | 0.7406 | 0.6905 | 0.7510 | 0.7089 | 0.7525 | 0.7518 | 0.7826 |
| 5 | 0.5273 | 0.4697 | 0.2452 | 0.5831 | 0.5845 | 0.4515 | 0.5311 | 0.0836 | 0.3070 | 0.2511 |

<img width="1590" height="889" alt="image" src="https://github.com/user-attachments/assets/427eface-7087-420f-801e-de829bce0def" />

<맞춤형 차원 축소 적용이후 각 채널과 폴드별 평균 절대 오차표와 그래프>

| Fold | CH-A1 | CH-A2 | CH-A3 | CH-A4 | CH-A5 | CH-B1 | CH-B2 | CH-B3 | CH-B4 | CH-B5 |  
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 0.0093 | 0.0092 | 0.0084 | 0.0081 | 0.0079 | 0.0100 | 0.0096 | 0.0088 | 0.0087 | 0.0101 |
| 2 | 0.0080 | 0.0081 | 0.0086 | 0.0084 | 0.0068 | 0.0069 | 0.0073 | 0.0069 | 0.0069 | 0.0068 | 
| 3 | 0.0071 | 0.0079 | 0.0068 | 0.0072 | 0.0095 | 0.0097 | 0.0087 | 0.0077 | 0.0067 | 0.0093 | 
| 4 | 0.0074 | 0.0102 | 0.0075 | 0.0071 | 0.0091 | 0.0074 | 0.0081 | 0.0072 | 0.0080 | 0.0080 | 
| 5 | 0.0068 | 0.0078 | 0.0069 | 0.0067 | 0.0066 | 0.0069 | 0.0063 | 0.0071 | 0.0093 | 0.0090 | 

<img width="1589" height="889" alt="image" src="https://github.com/user-attachments/assets/01fa83d1-1e07-4be2-88d7-18127f4903c4" />

PCA 적용 결과 결론
- 모델의 성능 개선과 해당 프로젝트의 가장 큰 문제인 5번째 폴드 성능 저하 문제를 해결하기 위해, 600여 개의 피처에 내재된 노이즈와 다중공선성을 제거하기 위해서 PCA 차원 축소 실험을 진행하였습니다. 결론부터 말하자면 PCA 모델은 기존에 비교 대상으로 600여 개의 피처를 전부 포함한 모델링 결과 보다 더 낮은 성능을 기록하였습니다. 즉, 성능 개선에는 실패를 하였습니다.
1. 결측값 처리의 함정
PCA를 적용하기 위해 필수적으로 진행을 했던 중앙값 기반의 결측값 처리는, LGBM 알고리즘이 자체적으로 처리할 수 있었던 결측값 자체가 가진 정보를 왜곡하는 역효과가 있습니다. `lag`나 `rolling` 피처가 생성되는 과정에서 필연적으로 발생하는 결측값은 'LOT의 시작' 또는 'LOT의 초반부'와 같은 중요한 구조적 정보를 담고 있었으나 인공적인 중위수 값으로 대체가 되면서 해당 정보 등이 유실되어 모델 성능이 저하된 원인 중 하나라고 추측할 수 있습니다.
2. 비정상성 데이터의 증거
각 교차 검증 폴드마다 최적의 주성분 개수가 84개에서 101개까지 변동하는 것을 확인할 수 있습니다. 이는 데이터의 내재적 구조 자체가 시간에 따라 계속해서 변하는 비정상성 데이터라는 증거라고 할 수 있습니다. 따라서, 전체 데이터에 대해 고정된 변환을 적용하는 PCA 방식은 이러한 데이터의 특성을 포착하는데 한계가 있었다는 것을 알 수 있습니다. 
3. 선형성의 한계
초기 실험에서 엘라스틱넷이라는 정규방정식 기반의 선형 회귀 모델링과 고유값 분해 기반의 PCA라는 두 선형 기법의 연속적인 실패는 해당 데이터를 가지고 모델의 예측력을 결정하는 중요도가 높은 피처들은 선형 부분 공간에 존재하지 않으면서 강력한 트리 기반의 LGBM 과 같은 트리 모델들이 포착할 수 있는 비선형 상호작용 속에 존재한다고 할 수 있습니다.

## 6. 최종 결론

해당 프로젝트는 `t+1` 예측이라는 초기 목표에 대한 한계를 인지하고, 보다 더 높은 비즈니스 가치를 가진 `t+10` 시점의 신호값 예측 문제로 전환을 하여 성공적인 결과를 얻어냈습니다. AutoML과 같은 자동 피처 엔지니어링이 아닌 수제작한 피처 엔지니어링과 모델링을 통해, 시계열 교차검증 기준 평균 `R² 0.728`이라는 예측 성능을 확보하였으며, 이는 선제적 대응 시스템 구축을 위한 기술적 기반을 확보했다고 할 수 있습니다. 

리스크 분석 및 향후 과제
본 모델의 안정적인 운영과 가치 극대화를 위해, 다음과 같은 리스크 요인을 인지하고 있으며, 이를 해결하기 위한 계획을 가지고 있습니다. 
- 최종 일반화 성능 검증: 홀드아웃 데이터셋을 통한 객관적인 성능 측정이 모델 신뢰도 확보의 최종 숙제입니다.
- 예측 안정성 강화: 폴드별 성능 편차(`R² std: 0.160`)는 모델의 강건성을 저해하는 핵심 리스크 입니다. 특히 성능이 취약한 3번째 폴드와 5번째 폴드 구간에 대한 심층 분석을 통해 모델의 안정성을 높여야 합니다.

따라서, 해당 프로젝트를 비즈니스 임팩트를 줄 수 있는 레벨로 발전시키기 위해 다음과 같은 3단계 방법들을 제안합니다. 

1. 홀드아웃 데이터셋을 이용한 최종 성능 검증: 모델 배포 전, 학습 과정에서 전혀 사용되지 않은 데이터를 시용하여 모델의 일반화 성능을 객관적으로 평가해야 합니다.
2. 모델의 강건성 강화: 폴드 별로 성능 편차가 크며 앞서 계속 언급을 했던대로 3번째 폴드와 5번째 폴드 구간에서 성능이 낮게 나옵니다. 해당 폴드의 데이터 특성을 심층 분석하여, 모델이 예측을 어려워하는 특정 조건을 파악하고 이를 보완할 수 있는 피처를 추가하거나 모델링 방법을 수정해야 합니다.
3. MLOps 파이프라인 구축을 통한 자동화: Concept Drift에 대응하기 위해, 새로운 데이터가 유입될 때마다 자동으로 모델을 재학습하고 성능을 모니터링하는 MLOps 파이프라인 구축이 필수적입니다. 특히, LGBM과 같은 트리 모델은 `partial_fit` 와 같은 메서드를 사용할 수 없기 때문에, 주기적인 완전 재학습을 자동화하는 것이 핵심 과제입니다.









